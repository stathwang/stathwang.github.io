<!DOCTYPE html>
<html lang="en">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="https://stathwang.github.io/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="https://stathwang.github.io/theme/pygments/monokai.min.css">
  <link rel="stylesheet" type="text/css" href="https://stathwang.github.io/theme/font-awesome/css/font-awesome.min.css">


    <link href="https://stathwang.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Seong Hyun Hwang Atom">



  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />

    <!-- Chrome, Firefox OS and Opera -->
    <meta name="theme-color" content="#333333">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#333333">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

<meta name="author" content="Seong Hyun Hwang" />
<meta name="description" content="The \(k\)-nearest neighbors algorithm is a simple, yet powerful machine learning technique used for classification and regression. The basic premise is to use closest known data points to make a prediction; for instance, if \(k = 3\), then we'd use 3 nearest neighbors of a point in the test set …" />
<meta name="keywords" content="k-nearest neighbors, classification, python">
<meta property="og:site_name" content="Seong Hyun Hwang"/>
<meta property="og:title" content="K-Nearest Neighbors from Scratch in Python"/>
<meta property="og:description" content="The \(k\)-nearest neighbors algorithm is a simple, yet powerful machine learning technique used for classification and regression. The basic premise is to use closest known data points to make a prediction; for instance, if \(k = 3\), then we'd use 3 nearest neighbors of a point in the test set …"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://stathwang.github.io/k-nearest-neighbors-from-scratch-in-python.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2017-03-16 23:16:00-04:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://stathwang.github.io/author/seong-hyun-hwang.html">
<meta property="article:section" content="Machine Learning"/>
<meta property="article:tag" content="k-nearest neighbors"/>
<meta property="article:tag" content="classification"/>
<meta property="article:tag" content="python"/>
<meta property="og:image" content="http://www.gravatar.com/avatar/ea0e94239070aef9781e64fb53facf13?s=120&d=http%3A%2F%2Fwww.example.com%2Fdefault.jpg">
  <title>Seong Hyun Hwang &ndash; K-Nearest Neighbors from Scratch in Python</title>
</head>
<body>
  <aside>
    <div>
      <a href="https://stathwang.github.io">
        <img src="http://www.gravatar.com/avatar/ea0e94239070aef9781e64fb53facf13?s=120&d=http%3A%2F%2Fwww.example.com%2Fdefault.jpg" alt="Seong Hyun Hwang" title="Seong Hyun Hwang">
      </a>
      <h1><a href="https://stathwang.github.io">Seong Hyun Hwang</a></h1>
<p>Data Scientist - Product Developer</p>      <nav>
        <ul class="list">
          <li><a href="https://stathwang.github.io/pages/about.html#about">about</a></li>
          <li><a href="https://stathwang.github.io/pages/projects.html#projects">projects</a></li>
        </ul>
      </nav>
      <ul class="social">
        <li><a class="sc-linkedin" href="https://www.linkedin.com/in/seonghyunhwang" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        <li><a class="sc-github" href="https://github.com/stathwang" target="_blank"><i class="fa fa-github"></i></a></li>
        <li><a class="sc-google" href="https://plus.google.com/112356517445062778569" target="_blank"><i class="fa fa-google"></i></a></li>
        <li><a class="sc-twitter" href="https://twitter.com/superhugehwang" target="_blank"><i class="fa fa-twitter"></i></a></li>
        <li><a class="sc-rss" href="//stathwang.github.io/feeds/all.atom.xml" target="_blank"><i class="fa fa-rss"></i></a></li>
      </ul>
    </div>
  </aside>
  <main>
    <nav>
      <a href="https://stathwang.github.io">Home</a>
      <a href="/archives.html">Archives</a>
      <a href="/categories.html">Categories</a>
      <a href="/tags.html">Tags</a>
      <a href="https://stathwang.github.io/feeds/all.atom.xml">Atom</a>
    </nav>

<article>
  <header>
    <h1 id="k-nearest-neighbors-from-scratch-in-python">K-Nearest Neighbors from Scratch in Python</h1>
    <p>Posted on March 2017 in <a href="https://stathwang.github.io/category/machine-learning.html">Machine Learning</a></p>
  </header>
  <div>
    <p><img alt="MNIST" src="https://stathwang.github.io/images/mnist.png"></p>
<p>The <span class="math">\(k\)</span>-nearest neighbors algorithm is a simple, yet powerful machine learning technique used for classification and regression. The basic premise is to use closest known data points to make a prediction; for instance, if <span class="math">\(k = 3\)</span>, then we'd use 3 nearest neighbors of a point in the test set. In this post, I'm going to use <code>kNN</code> for classifying hand-written digits from 0 to 9 as shown in the picture above. Here's the pseudocode for classification:</p>
<ol>
<li>Choose the number of nearest neighbors i.e. <span class="math">\(k = 5\)</span>.</li>
<li>For each data point in the test set:<ul>
<li>Calculate the distance from the point to each of <span class="math">\(k\)</span> nearest neighbors in the training set.</li>
<li>Use the majority class voting among <span class="math">\(k\)</span> training points to assign the best class to the test point.</li>
</ul>
</li>
</ol>
<p>For regression, the algorithm takes the average of <span class="math">\(k\)</span> training points instead of the majority class vote. It's important to be able to reimplement machine learning algorithms from scratch without using scikit-learn. Below is the Python script I've written that searches a sorted list in <span class="math">\(O(logK)\)</span> which could be improved with a ball tree or a kd tree. The <code>get_data()</code> function retrieves the training <a href="https://www.kaggle.com/c/digit-recognizer/data">MNIST dataset</a> downloaded to my working directory, <code>fit()</code> function just stores the training data and class labels, and the <code>predict()</code> function does all the job of classifying the test labels. I choose the best <span class="math">\(k\)</span> value that minimizes the misclassification error on a validation set. I use a repeated cross-validation here, running 10 repeats of 10-fold CV of the training set for each <span class="math">\(k\)</span> from 1 to 19, but since the CV score of each repeat doesn't vary much, it should be fine to do a single 10-fold CV to increase computational efficiency. I also randomly take 3000 data points from the original training set and set aside <span class="math">\(1/3\)</span> of them to be the test set since the original training set is quite large. I use the simple <code>kNN</code> algorithm here but there exist more robust <code>kNN</code> algorithms out there such as the <code>Weighted kNN</code> which weights each data point by its distance to the training point.</p>
<div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/python</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sortedcontainers</span> <span class="kn">import</span> <span class="n">SortedList</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">randint</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="n">random</span>

<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">print</span> <span class="s1">&#39;Reading in and transforming data...&#39;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;train.csv&#39;</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">/</span> <span class="mf">255.0</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">limit</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">limit</span><span class="p">],</span> <span class="n">Y</span><span class="p">[:</span><span class="n">limit</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>

<span class="k">class</span> <span class="nc">KNN</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">classify</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classify</span> <span class="o">=</span> <span class="n">classify</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">sl</span> <span class="o">=</span> <span class="n">SortedList</span><span class="p">(</span><span class="n">load</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">xt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">):</span>
                <span class="n">diff</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">xt</span>
                <span class="n">d</span> <span class="o">=</span> <span class="n">diff</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sl</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">:</span>
                    <span class="n">sl</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">d</span> <span class="o">&lt;</span> <span class="n">sl</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]:</span>
                        <span class="k">del</span> <span class="n">sl</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                        <span class="n">sl</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">classify</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
                <span class="n">votes</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sl</span><span class="p">:</span>
                    <span class="n">votes</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">votes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="n">max_votes</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">max_votes_class</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
                <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">votes</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="n">max_votes</span><span class="p">:</span>
                        <span class="n">max_votes</span> <span class="o">=</span> <span class="n">count</span>
                        <span class="n">max_votes_class</span> <span class="o">=</span> <span class="n">v</span>
                <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_votes_class</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">sl</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="n">P</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">classify</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">P</span> <span class="o">!=</span> <span class="n">Y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">P</span> <span class="o">-</span> <span class="n">Y</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="mi">3000</span><span class="p">)</span>
    <span class="n">Ntrain</span> <span class="o">=</span> <span class="mi">2000</span>
    <span class="n">Xtrain</span><span class="p">,</span> <span class="n">Ytrain</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">Ntrain</span><span class="p">],</span> <span class="n">Y</span><span class="p">[:</span><span class="n">Ntrain</span><span class="p">]</span>
    <span class="n">Xtest</span><span class="p">,</span> <span class="n">Ytest</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">Ntrain</span><span class="p">:],</span> <span class="n">Y</span><span class="p">[</span><span class="n">Ntrain</span><span class="p">:]</span>

    <span class="n">t0</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
    <span class="n">fold</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">smoothness</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">kcv_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">):</span>
        <span class="n">re_scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">smoothness</span><span class="p">):</span>
            <span class="n">rlist</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fold</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">)):</span>
                <span class="n">seed</span><span class="p">(</span><span class="n">u</span> <span class="o">+</span> <span class="n">v</span><span class="o">*</span><span class="mi">16000000</span><span class="p">)</span>
                <span class="n">rlist</span><span class="p">[</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">9</span><span class="p">)]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
            <span class="n">r_fold_size</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">rlist</span><span class="p">]</span>
            <span class="n">R</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">r_fold_size</span><span class="p">)</span>
            <span class="n">cv_scores</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rlist</span><span class="p">)):</span>
                <span class="n">xtrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">rlist</span><span class="p">[</span><span class="n">w</span><span class="p">]])</span>
                <span class="n">ytrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">Ytrain</span><span class="p">)</span> <span class="k">if</span> <span class="n">j</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">rlist</span><span class="p">[</span><span class="n">w</span><span class="p">]])</span>
                <span class="n">xtest</span> <span class="o">=</span> <span class="n">Xtrain</span><span class="p">[</span><span class="n">rlist</span><span class="p">[</span><span class="n">w</span><span class="p">]]</span>
                <span class="n">ytest</span> <span class="o">=</span> <span class="n">Ytrain</span><span class="p">[</span><span class="n">rlist</span><span class="p">[</span><span class="n">w</span><span class="p">]]</span>
                <span class="n">knn</span> <span class="o">=</span> <span class="n">KNN</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">classify</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
                <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
                <span class="n">cv_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">))</span>
            <span class="n">avg_score</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">a</span> <span class="o">*</span> <span class="n">b</span> <span class="o">/</span> <span class="n">R</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">,</span> <span class="n">r_fold_size</span><span class="p">)])</span>
            <span class="n">re_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_score</span><span class="p">)</span>
        <span class="n">kcv_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">re_scores</span><span class="p">))</span>
        <span class="k">print</span> <span class="s1">&#39;Done with k =&#39;</span><span class="p">,</span> <span class="n">k</span>
    <span class="k">print</span> <span class="s1">&#39;Repeated CV time:&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span>

    <span class="n">k_optim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">kcv_scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">print</span> <span class="n">kcv_scores</span>
    <span class="k">print</span> <span class="s1">&#39;Min error:&#39;</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">kcv_scores</span><span class="p">)</span>
    <span class="k">print</span> <span class="s1">&#39;Optimal k:&#39;</span><span class="p">,</span> <span class="n">k_optim</span>

    <span class="n">t0</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNN</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">k_optim</span><span class="p">,</span> <span class="n">classify</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">Ytrain</span><span class="p">)</span>
    <span class="k">print</span> <span class="s1">&#39;Test error:&#39;</span><span class="p">,</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">Ytest</span><span class="p">)</span>
    <span class="k">print</span> <span class="s1">&#39;Test time:&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span>
    <span class="k">print</span> <span class="s1">&#39;Done!&#39;</span>
</pre></div>


<p>Here is the plot of misclassification error by <span class="math">\(k\)</span> from repeated cross validation. The minimum validation error is 0.0974 achieved when <span class="math">\(k = 3\)</span>. Using this optimal value of <span class="math">\(k\)</span>, we'd fit a <code>kNN</code> on the entire training set and predict on the test set. The test error is 0.1 which is very close to the validation error we got for <span class="math">\(k = 3\)</span>. The model prediction takes about a minute. For more information about the mechanism of <code>kNN</code>, take a look at <a href="https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor/">this</a> blog post.</p>
<p><img alt="ErrorPlot" src="https://stathwang.github.io/images/misclass.png"></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="https://stathwang.github.io/tag/k-nearest-neighbors.html">k-nearest neighbors</a>
      <a href="https://stathwang.github.io/tag/classification.html">classification</a>
      <a href="https://stathwang.github.io/tag/python.html">python</a>
    </p>
  </div>
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'thedatalogical';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</article>

    <hr />
    <p />
    <!-- Begin MailChimp Signup Form -->
<link href="//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}
  /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
     We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//github.us1.list-manage.com/subscribe/post?u=0f2c943c221c777ef88591fb6&amp;id=6cf4236c90" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
  <label for="mce-EMAIL">Subscribe to my sporadic data science newsletter and blog post</label>
  <input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_0f2c943c221c777ef88591fb6_6cf4236c90" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>
<br />
<br />

<!--End mc_embed_signup-->

    <footer>
<p>
  &copy; Seong Hyun Hwang 2015 - 2017 - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>
</p>
<p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
         src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
  </main>

<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-69797568-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->
  <script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/signup-forms/popup/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script><script type="text/javascript">require(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us1.list-manage.com","uuid":"0f2c943c221c777ef88591fb6","lid":"6cf4236c90"}) })</script>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Seong Hyun Hwang ",
  "url" : "https://stathwang.github.io",
  "image": "http://www.gravatar.com/avatar/ea0e94239070aef9781e64fb53facf13?s=120&d=http%3A%2F%2Fwww.example.com%2Fdefault.jpg",
  "description": "Seong Hyun Hwang's Thoughts and Writings"
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "name": "K-Nearest Neighbors from Scratch in Python",
  "headline": "K-Nearest Neighbors from Scratch in Python",
  "datePublished": "2017-03-16 23:16:00-04:00",
  "dateModified": "",
  "author": {
    "@type": "Person",
    "name": "Seong Hyun Hwang",
    "url": "https://stathwang.github.io/author/seong-hyun-hwang.html"
  },
  "image": "http://www.gravatar.com/avatar/ea0e94239070aef9781e64fb53facf13?s=120&d=http%3A%2F%2Fwww.example.com%2Fdefault.jpg",
  "url": "https://stathwang.github.io/k-nearest-neighbors-from-scratch-in-python.html",
  "description": "The \(k\)-nearest neighbors algorithm is a simple, yet powerful machine learning technique used for classification and regression. The basic premise is to use closest known data points to make a prediction; for instance, if \(k = 3\), then we'd use 3 nearest neighbors of a point in the test set …"
}
</script></body>
</html>